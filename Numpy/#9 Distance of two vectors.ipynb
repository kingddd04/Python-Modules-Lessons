{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6f1917",
   "metadata": {},
   "source": [
    "# 📏 Distance Between Vectors\n",
    "\n",
    "To calculate the distance between two vectors, we take the norm (or magnitude) of the difference between them. This gives us the Euclidean distance, which represents how far apart the vectors are in space.\n",
    "\n",
    "Mathematically:\n",
    "If **u** and **v** are two vectors, the distance **d** between them is:\n",
    "\n",
    "**d = ||u - v||**\n",
    "\n",
    "Where:\n",
    "- `|| · ||` denotes the norm\n",
    "- `u - v` is the vector difference\n",
    "\n",
    "This method works for vectors in any dimensional space and is commonly used in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "# creating sample datas \n",
    "import numpy as np\n",
    "\n",
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([4,6,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532124f",
   "metadata": {},
   "source": [
    "# 🧮 Linear Algebra Basics for Machine Learning\n",
    "\n",
    "## 📏 Vector Norm: L1 Distance (Manhattan Distance)\n",
    "\n",
    "This distance measures the sum of the absolute differences between the components of two vectors,  \n",
    "as if we were moving along a \"Manhattan\" grid (whose streets typically follow straight lines).\n",
    "\n",
    "### 🔍 Key Characteristics:\n",
    "- Less sensitive to extreme values compared to L2 norm.\n",
    "- Large differences contribute linearly.\n",
    "- Useful when we want to reduce the influence of very large values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2d1f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance between v1 and v2 :  7.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Manhattan distance between v1 and v2 : \" , np.linalg.norm(v1-v2,1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d8c016",
   "metadata": {},
   "source": [
    "# 🧮 Linear Algebra Basics for Machine Learning\n",
    "\n",
    "## 📐 Vector Norm: L2 Distance (Euclidean Distance)\n",
    "\n",
    "This corresponds to the Euclidean (straight-line) distance between two points in vector space.  \n",
    "It is the most common distance measure in geometry and machine learning.\n",
    "\n",
    "### 🔍 Key Characteristics:\n",
    "- It represents the “straight-line” distance.\n",
    "- More sensitive to large values, since differences are squared.\n",
    "- It is the most widely used metric in machine learning and geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb9d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between v1 and v2 :  5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean distance between v1 and v2 : \" , np.linalg.norm(v1-v2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43810f6",
   "metadata": {},
   "source": [
    "# 🧮 Linear Algebra Basics for Machine Learning\n",
    "\n",
    "## 🧭 Vector Norm: Chebyshev Distance\n",
    "\n",
    "This distance measures the greatest absolute difference between the components of two vectors.  \n",
    "It reflects the number of moves required in a grid where diagonal movement is allowed, like a king on a chessboard.\n",
    "\n",
    "### 🔍 Key Characteristics:\n",
    "- Also known as the **maximum norm** or **L∞ norm**.\n",
    "- Captures the **largest** single-axis difference between two vectors.\n",
    "- Useful in scenarios where movement is constrained by maximum steps in any direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120b675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chebyshnev distance between v1 and v2 :  4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Chebyshnev distance between v1 and v2 : \" , np.linalg.norm(v1-v2, np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2098180",
   "metadata": {},
   "source": [
    "# 🧮 Linear Algebra Basics for Machine Learning\n",
    "\n",
    "## 📊 Vector Norm: Minkowski Distance\n",
    "\n",
    "The Minkowski distance is a generalized metric that includes both L1 (Manhattan) and L2 (Euclidean) distances as special cases.  \n",
    "It is defined by a parameter **p**, which determines the type of norm used.\n",
    "\n",
    "### 🔍 Key Characteristics:\n",
    "- When **p = 1**, it becomes the **Manhattan Distance**.\n",
    "- When **p = 2**, it becomes the **Euclidean Distance**.\n",
    "- When **p -> np.inf** it becomes the Chebyshev distance\n",
    "- For other values of **p**, it defines a flexible distance metric.\n",
    "- When building ai models modifing the parater p can change the overall interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e4875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minkovoski distance result :  7.0\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "minkowski_distance = np.sum(np.abs(v1 - v2) ** p) ** (1 / p) # general formula for minkowski\n",
    "\n",
    "print(\"Minkovoski distance result : \", minkowski_distance)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
